from ultralytics import YOLO
import cv2
from glob import glob
from PIL import Image
import os

model = YOLO("yolov8-trained.pt")

video_path = './Videos/out4.mp4'
cap = cv2.VideoCapture(video_path)
i = 0

while cap.isOpened():
    ret, frame = cap.read()
    if ret:
        cv2.imwrite(f'./Temporary/frame{i}.jpg', frame)
        results = model([f'./Temporary/frame{i}.jpg'])
       
        for result in results:
            boxes = result.boxes  # Boxes object for bbox outputs
            masks = result.masks  # Masks object for segmentation masks outputs
            keypoints = result.keypoints  # Keypoints object for pose outputs
            probs = result.probs  # Probs object for classification outputs
    
        for idx, r in enumerate(results):
            im_array = r.plot()  # plot a BGR numpy array of predictions
            image = Image.fromarray(im_array[..., ::-1])  # RGB PIL image
            
            # Save the processed image by overwriting the original
            filename = f'./Temporary/frame{i}.jpg'
            image.save(filename)
            
            i += 20
            cap.set(cv2.CAP_PROP_POS_FRAMES, i)
            print(i)
    else:
        cap.release()
        break
